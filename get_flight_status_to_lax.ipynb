{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import ssl\n",
    "import time\n",
    "import json\n",
    "\n",
    "database = \"database.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_page(soup):\n",
    "    try:\n",
    "        return soup.find_all(\"table\")[0].find_all(\"div\")[0].text\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "def get_table_data(soup):\n",
    "    \"\"\"\n",
    "    @param soup object of a page\n",
    "    @return list of dict : [{...}, {...}, {...}]\n",
    "    each object in list represent each row in the table\n",
    "    \n",
    "    {\n",
    "        \"airline\": \"\",\n",
    "        \"flight\": \"\",\n",
    "        \"from\": \"\",\n",
    "        \"scheduled\": \"\",\n",
    "        \"actual\": \"\",\n",
    "        \"gate\": \"\",\n",
    "    \n",
    "    }\n",
    "    \"\"\"\n",
    "    table = soup.find_all(\"table\", class_=\"my_flight\")\n",
    "    parsed_table = list()\n",
    "    for row in table:\n",
    "        if not row.contents: # malform row\n",
    "            continue\n",
    "        parsed_row = dict()\n",
    "        columns = row.contents[0].find_all(\"td\")\n",
    "        if len(columns) != 10: # malform row\n",
    "            continue\n",
    "        parsed_row[\"airline\"] = columns[1].text\n",
    "        parsed_row[\"flight\"] = columns[2].text\n",
    "        parsed_row[\"airport\"] = columns[4].text\n",
    "        parsed_row[\"city\"] = columns[5].text\n",
    "        parsed_row[\"scheduled\"] = columns[6].text\n",
    "        parsed_row[\"actual\"] = columns[7].text\n",
    "        parsed_row[\"gate\"] = columns[8].text\n",
    "        parsed_row[\"status\"] = columns[9].text\n",
    "        parsed_table.append(parsed_row)\n",
    "            \n",
    "    return parsed_table\n",
    "\n",
    "\n",
    "def scraped():\n",
    "    \"\"\"\n",
    "    @return {\"<date as shown on the top of the page>\" : <list of dict as return from get_table_data>}\n",
    "    \"\"\"\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    url = \"https://www.airport-la.com/lax/arrivals?t=\"\n",
    "    htmls = dict()\n",
    "\n",
    "    for i in range(-10,21):\n",
    "        with urllib.request.urlopen(url + str(i)) as response:\n",
    "            html = response.read()\n",
    "        soup = BeautifulSoup(html)\n",
    "        date = get_datetime_page(soup)\n",
    "        if date:\n",
    "            data = get_table_data(soup)\n",
    "            htmls[date] = data     \n",
    "    return htmls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Daily\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "with open(database, \"r\") as f:\n",
    "    old = json.load(f)\n",
    "    \n",
    "old[now] = scraped()\n",
    "\n",
    "\n",
    "with open(database, \"w\") as f:\n",
    "    json.dump(old, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
